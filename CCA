{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNWY31ECPOOpQe5t3HLjS6q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["connected_component_analysis"],"metadata":{"id":"zaAQgeRruvvq"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"TWBZtQzyEFtZ"},"outputs":[],"source":["import numpy as np\n","from scipy.ndimage import label\n","import imageio.v2 as imageio\n","\n","def connected_component_analysis(pred_mask, gt_mask, connectivity=2, threshold=0.5):\n","    \"\"\"\n","    Perform Connected Component Analysis on predicted and ground truth masks.\n","\n","    Parameters:\n","    - pred_mask: NumPy array with float values (probability map or binary)\n","    - gt_mask: NumPy array with float/binary values (ground truth mask)\n","    - connectivity: 1 for 4-connectivity, 2 for 8-connectivity (2D); 1, 2, 3 for 6-, 18-, 26-connectivity (3D)\n","    - threshold: Float (e.g., 0.5). Pixels >= threshold are set to 1, others to 0.\n","\n","    Returns:\n","    - Dictionary with number of components, component difference, and size of largest component\n","    \"\"\"\n","\n","    # Convert probability masks to binary\n","    pred_binary = (pred_mask >= threshold).astype(np.uint8)\n","\n","    # Define connectivity structure\n","    if pred_mask.ndim == 2:\n","        structure = np.ones((3, 3), dtype=np.uint8) if connectivity == 2 else np.array([[0,1,0],[1,1,1],[0,1,0]], dtype=np.uint8)\n","    else:\n","        if connectivity == 1:\n","            structure = np.zeros((3, 3, 3), dtype=np.uint8)\n","            structure[1, 1, :] = 1\n","            structure[1, :, 1] = 1\n","            structure[:, 1, 1] = 1\n","        elif connectivity == 2:\n","            structure = np.ones((3, 3, 3), dtype=np.uint8)\n","            structure[0, 0, 0] = structure[0, 0, 2] = structure[0, 2, 0] = structure[0, 2, 2] = 0\n","            structure[2, 0, 0] = structure[2, 0, 2] = structure[2, 2, 0] = structure[2, 2, 2] = 0\n","        else:\n","            structure = np.ones((3, 3, 3), dtype=np.uint8)\n","\n","    # Perform CCA\n","    pred_labeled, pred_num = label(pred_binary, structure=structure, output=np.int32)\n","    gt_labeled, gt_num = label(gt_mask, structure=structure, output=np.int32)\n","\n","    # Component sizes\n","    if pred_num > 0:\n","        pred_sizes = np.bincount(pred_labeled.flat)[1:]\n","        largest_component_size = np.max(pred_sizes)\n","    else:\n","        largest_component_size = 0\n","\n","    return {\n","        'pred_components': pred_num,\n","        'gt_components': gt_num,\n","        'component_difference': abs(pred_num - gt_num),\n","        'largest_component_size': largest_component_size,\n","        'fragmentation_penalty': max(0, pred_num - 1),\n","    }\n","\n","# Example usage\n","if __name__ == \"__main__\":\n","    pred_mask = imageio.imread('path/to/pred_mask.png') / 255.0  # or load a .npy probability array\n","    gt_mask = imageio.imread('path/to/gt_mask.png') / 255.0\n","\n","    # CCA with 0.5 threshold\n","    results = connected_component_analysis(pred_mask, gt_mask, connectivity=2, threshold=0.5)\n","\n","    print(\"Connected Component Analysis Results:\")\n","    for key, value in results.items():\n","        print(f\"{key}: {value}\")\n"]},{"cell_type":"markdown","source":["**chamfer_distance**"],"metadata":{"id":"JFYzNQXMu5dj"}},{"cell_type":"markdown","source":["![cd.PNG](data:image/png;base64,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)"],"metadata":{"id":"1W-l7KQlvKb1"}},{"cell_type":"code","source":["import numpy as np\n","from skimage.morphology import skeletonize, skeletonize_3d\n","from scipy.spatial.distance import cdist\n","import imageio.v2 as imageio\n","import matplotlib.pyplot as plt\n","\n","def binarize_mask(prob_mask, threshold=0.5):\n","    \"\"\"Convert probability mask to binary using a threshold.\"\"\"\n","    return (prob_mask >= threshold).astype(np.uint8)\n","\n","def get_skeleton(mask):\n","    \"\"\"Skeletonize the binary mask. Automatically picks 2D or 3D.\"\"\"\n","    if mask.ndim == 2:\n","        return skeletonize(mask)\n","    elif mask.ndim == 3:\n","        return skeletonize_3d(mask)\n","    else:\n","        raise ValueError(\"Only 2D or 3D masks are supported.\")\n","\n","def get_skeleton_points(skeleton):\n","    \"\"\"Extract coordinates of skeleton pixels/voxels.\"\"\"\n","    return np.argwhere(skeleton)\n","\n","def chamfer_distance(points1, points2):\n","    \"\"\"Compute symmetric Chamfer Distance between two point sets.\"\"\"\n","    if len(points1) == 0 or len(points2) == 0:\n","        return float('inf')  # Completely disconnected\n","\n","    # One-way average distances\n","    dist_1 = cdist(points1, points2).min(axis=1)\n","    dist_2 = cdist(points2, points1).min(axis=1)\n","\n","    return dist_1.mean() + dist_2.mean()\n","\n","def evaluate_chamfer(gt_mask, pred_mask_prob, threshold=0.5, visualize=False):\n","    # Step 1: Binarize predicted mask\n","    pred_mask_bin = binarize_mask(pred_mask_prob, threshold)\n","\n","    # Step 2: Skeletonize\n","    gt_skel = get_skeleton(gt_mask)\n","    pred_skel = get_skeleton(pred_mask_bin)\n","\n","    # Step 3: Extract skeleton points\n","    gt_pts = get_skeleton_points(gt_skel)\n","    pred_pts = get_skeleton_points(pred_skel)\n","\n","    # Step 4: Compute Chamfer Distance\n","    chamfer = chamfer_distance(gt_pts, pred_pts)\n","\n","    # Step 5 (Optional): Visualize\n","    if visualize and gt_mask.ndim == 2:\n","        plt.figure(figsize=(6, 6))\n","        plt.imshow(np.zeros_like(gt_mask), cmap='gray')\n","        plt.scatter(gt_pts[:, 1], gt_pts[:, 0], s=2, color='green', label='GT Skeleton')\n","        plt.scatter(pred_pts[:, 1], pred_pts[:, 0], s=2, color='red', label='Pred Skeleton')\n","        plt.title(f\"Chamfer Distance: {chamfer:.4f}\")\n","        plt.legend()\n","        plt.axis('off')\n","        plt.tight_layout()\n","        plt.show()\n","\n","    return chamfer\n","\n","# === Example usage ===\n","if __name__ == \"__main__\":\n","    # Load 2D grayscale images (as probability and binary masks)\n","    gt_path = \"path/to/ground_truth_mask.png\"\n","    pred_path = \"path/to/predicted_prob_mask.png\"  # Values in [0, 255] or [0, 1]\n","\n","    gt_mask = imageio.imread(gt_path) > 0  # Make binary\n","    pred_mask_prob = imageio.imread(pred_path) / 255.0  # Normalize to [0, 1]\n","\n","    chamfer = evaluate_chamfer(gt_mask, pred_mask_prob, threshold=0.5, visualize=True)\n","    print(f\"Chamfer Distance = {chamfer:.4f}\")\n"],"metadata":{"id":"Srl08HUhuqXn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" hausdorff distance  and HD95"],"metadata":{"id":"z4pf1u7W9iE8"}},{"cell_type":"code","source":["import numpy as np\n","import imageio.v2 as imageio\n","from medpy.metric.binary import hd, hd95\n","from scipy.ndimage import binary_erosion\n","from skimage.morphology import ball, disk\n","\n","def binarize_mask(prob_mask, threshold=0.5):\n","    \"\"\"Convert probability mask to binary using a threshold.\"\"\"\n","    return (prob_mask >= threshold).astype(np.uint8)\n","\n","def compute_hd_hd95(gt_mask, pred_prob, threshold=0.5):\n","    \"\"\"Compute Hausdorff Distance and 95th percentile HD.\"\"\"\n","    pred_mask = binarize_mask(pred_prob, threshold)\n","\n","    if gt_mask.shape != pred_mask.shape:\n","        raise ValueError(\"Shape mismatch between GT and prediction.\")\n","\n","    # Ensure masks are binary (0, 1)\n","    gt_mask = gt_mask.astype(bool)\n","    pred_mask = pred_mask.astype(bool)\n","\n","    # Check for completely empty masks\n","    if not np.any(gt_mask) or not np.any(pred_mask):\n","        return {\n","            'hd': float('inf'),\n","            'hd95': float('inf'),\n","            'status': 'failure',\n","            'reason': 'Empty mask in GT or Prediction'\n","        }\n","\n","    # Compute metrics using medpy\n","    hausdorff = hd(pred_mask, gt_mask)\n","    hausdorff_95 = hd95(pred_mask, gt_mask)\n","\n","    return {\n","        'hd': hausdorff,\n","        'hd95': hausdorff_95,\n","        'status': 'success'\n","    }\n","\n","# === Example usage ===\n","if __name__ == \"__main__\":\n","    # Replace with your actual image paths\n","    gt_path = \"path/to/gt_mask.png\"           # Ground truth mask (binary)\n","    pred_path = \"path/to/predicted_prob.png\"  # Predicted mask (probabilities)\n","\n","    # Load masks\n","    gt_mask = imageio.imread(gt_path) > 0         # Make binary\n","    pred_prob = imageio.imread(pred_path) / 255.0 # Normalize to [0, 1] if needed\n","\n","    results = compute_hd_hd95(gt_mask, pred_prob, threshold=0.5)\n","\n","    print(\"Hausdorff Distance Results:\")\n","    for key, value in results.items():\n","        print(f\"{key}: {value}\")\n"],"metadata":{"id":"gwKbwkb69fc6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -U openmim\n","!mim install mmcv-lite"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AhTHPRG3dcYw","executionInfo":{"status":"ok","timestamp":1752958461573,"user_tz":-330,"elapsed":20532,"user":{"displayName":"Minindu Liyanage","userId":"15262789509466583134"}},"outputId":"5953eb6d-953c-4ee4-c2ea-ac5ceb23bae7"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openmim in /usr/local/lib/python3.11/dist-packages (0.3.9)\n","Requirement already satisfied: Click in /usr/local/lib/python3.11/dist-packages (from openmim) (8.2.1)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from openmim) (0.4.6)\n","Requirement already satisfied: model-index in /usr/local/lib/python3.11/dist-packages (from openmim) (0.1.11)\n","Requirement already satisfied: opendatalab in /usr/local/lib/python3.11/dist-packages (from openmim) (0.0.10)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from openmim) (2.2.2)\n","Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.11/dist-packages (from openmim) (24.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from openmim) (2.28.2)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from openmim) (13.4.2)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from openmim) (0.9.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from model-index->openmim) (6.0.2)\n","Requirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (from model-index->openmim) (3.8.2)\n","Requirement already satisfied: ordered-set in /usr/local/lib/python3.11/dist-packages (from model-index->openmim) (4.1.0)\n","Requirement already satisfied: pycryptodome in /usr/local/lib/python3.11/dist-packages (from opendatalab->openmim) (3.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opendatalab->openmim) (4.65.2)\n","Requirement already satisfied: openxlab in /usr/local/lib/python3.11/dist-packages (from opendatalab->openmim) (0.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->openmim) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->openmim) (3.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->openmim) (1.26.20)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->openmim) (2025.7.14)\n","Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->openmim) (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->openmim) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->openmim) (2023.4)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->openmim) (2025.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->openmim) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->openmim) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->openmim) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->openmim) (1.17.0)\n","Requirement already satisfied: filelock~=3.14.0 in /usr/local/lib/python3.11/dist-packages (from openxlab->opendatalab->openmim) (3.14.0)\n","Requirement already satisfied: oss2~=2.17.0 in /usr/local/lib/python3.11/dist-packages (from openxlab->opendatalab->openmim) (2.17.0)\n","Requirement already satisfied: packaging~=24.0 in /usr/local/lib/python3.11/dist-packages (from openxlab->opendatalab->openmim) (24.2)\n","Requirement already satisfied: setuptools~=60.2.0 in /usr/local/lib/python3.11/dist-packages (from openxlab->opendatalab->openmim) (60.2.0)\n","Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.11/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (1.7)\n","Requirement already satisfied: aliyun-python-sdk-kms>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (2.16.5)\n","Requirement already satisfied: aliyun-python-sdk-core>=2.13.12 in /usr/local/lib/python3.11/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (2.16.0)\n","Requirement already satisfied: jmespath<1.0.0,>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (0.10.0)\n","Requirement already satisfied: cryptography>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (43.0.3)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=3.0.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (1.17.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=3.0.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (2.22)\n","Looking in links: https://download.openmmlab.com/mmcv/dist/cu124/torch2.6.0/index.html\n","Collecting mmcv-lite\n","  Downloading mmcv_lite-2.2.0-py2.py3-none-any.whl.metadata (2.4 kB)\n","Collecting addict (from mmcv-lite)\n","  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n","Collecting mmengine>=0.3.0 (from mmcv-lite)\n","  Downloading mmengine-0.10.7-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mmcv-lite) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mmcv-lite) (24.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from mmcv-lite) (11.2.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from mmcv-lite) (6.0.2)\n","Collecting yapf (from mmcv-lite)\n","  Downloading yapf-0.43.0-py3-none-any.whl.metadata (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.11/dist-packages (from mmcv-lite) (4.11.0.86)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mmengine>=0.3.0->mmcv-lite) (3.10.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from mmengine>=0.3.0->mmcv-lite) (13.4.2)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from mmengine>=0.3.0->mmcv-lite) (3.1.0)\n","Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.11/dist-packages (from yapf->mmcv-lite) (4.3.8)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv-lite) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv-lite) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv-lite) (4.58.5)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv-lite) (1.4.8)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv-lite) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv-lite) (2.9.0.post0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->mmengine>=0.3.0->mmcv-lite) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->mmengine>=0.3.0->mmcv-lite) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.3.0->mmcv-lite) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.3.0->mmcv-lite) (1.17.0)\n","Downloading mmcv_lite-2.2.0-py2.py3-none-any.whl (732 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m732.3/732.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mmengine-0.10.7-py3-none-any.whl (452 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.7/452.7 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Downloading yapf-0.43.0-py3-none-any.whl (256 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: addict, yapf, mmengine, mmcv-lite\n","Successfully installed addict-2.4.0 mmcv-lite-2.2.0 mmengine-0.10.7 yapf-0.43.0\n"]}]},{"cell_type":"code","source":["import argparse\n","import os\n","import os.path as osp\n","import tempfile\n","import zipfile\n","\n","import cv2\n","import mmcv\n","\n","\n","def parse_args():\n","    parser = argparse.ArgumentParser(\n","        description='Convert DRIVE dataset to mmsegmentation format')\n","    parser.add_argument(\n","        'training_path',default='data/DRIVE/training.zip' ,help='the training part of DRIVE dataset')\n","    parser.add_argument(\n","        'testing_path',default='data/DRIVE/test.zip', help='the testing part of DRIVE dataset')\n","    parser.add_argument('--tmp_dir', help='path of the temporary directory')\n","    parser.add_argument('-o', '--out_dir', help='output path')\n","    args = parser.parse_args()\n","    return args\n","\n","\n","def main():\n","    args = parse_args()\n","    training_path = args.training_path\n","    testing_path = args.testing_path\n","    if args.out_dir is None:\n","        out_dir = osp.join('data', 'DRIVE')\n","    else:\n","        out_dir = args.out_dir\n","\n","    print('Making directories...')\n","    mmcv.mkdir_or_exist(out_dir)\n","    mmcv.mkdir_or_exist(osp.join(out_dir, 'images'))\n","    mmcv.mkdir_or_exist(osp.join(out_dir, 'images', 'training'))\n","    mmcv.mkdir_or_exist(osp.join(out_dir, 'images', 'validation'))\n","    mmcv.mkdir_or_exist(osp.join(out_dir, 'annotations'))\n","    mmcv.mkdir_or_exist(osp.join(out_dir, 'annotations', 'training'))\n","    mmcv.mkdir_or_exist(osp.join(out_dir, 'annotations', 'validation'))\n","\n","    with tempfile.TemporaryDirectory(dir=args.tmp_dir) as tmp_dir:\n","        print('Extracting training.zip...')\n","        zip_file = zipfile.ZipFile(training_path)\n","        zip_file.extractall(tmp_dir)\n","\n","        print('Generating training dataset...')\n","        now_dir = osp.join(tmp_dir, 'training', 'images')\n","        for img_name in os.listdir(now_dir):\n","            img = mmcv.imread(osp.join(now_dir, img_name))\n","            mmcv.imwrite(\n","                img,\n","                osp.join(\n","                    out_dir, 'images', 'training',\n","                    osp.splitext(img_name)[0].replace('_training', '') +\n","                    '.png'))\n","\n","        now_dir = osp.join(tmp_dir, 'training', '1st_manual')\n","        for img_name in os.listdir(now_dir):\n","            cap = cv2.VideoCapture(osp.join(now_dir, img_name))\n","            ret, img = cap.read()\n","            mmcv.imwrite(\n","                img[:, :, 0] // 128,\n","                osp.join(out_dir, 'annotations', 'training',\n","                         osp.splitext(img_name)[0] + '.png'))\n","\n","        print('Extracting test.zip...')\n","        zip_file = zipfile.ZipFile(testing_path)\n","        zip_file.extractall(tmp_dir)\n","\n","        print('Generating validation dataset...')\n","        now_dir = osp.join(tmp_dir, 'test', 'images')\n","        for img_name in os.listdir(now_dir):\n","            img = mmcv.imread(osp.join(now_dir, img_name))\n","            mmcv.imwrite(\n","                img,\n","                osp.join(\n","                    out_dir, 'images', 'validation',\n","                    osp.splitext(img_name)[0].replace('_test', '') + '.png'))\n","\n","        now_dir = osp.join(tmp_dir, 'test', '1st_manual')\n","        if osp.exists(now_dir):\n","            for img_name in os.listdir(now_dir):\n","                cap = cv2.VideoCapture(osp.join(now_dir, img_name))\n","                ret, img = cap.read()\n","                # The annotation img should be divided by 128, because some of\n","                # the annotation imgs are not standard. We should set a\n","                # threshold to convert the nonstandard annotation imgs. The\n","                # value divided by 128 is equivalent to '1 if value >= 128\n","                # else 0'\n","                mmcv.imwrite(\n","                    img[:, :, 0] // 128,\n","                    osp.join(out_dir, 'annotations', 'validation',\n","                             osp.splitext(img_name)[0] + '.png'))\n","\n","        now_dir = osp.join(tmp_dir, 'test', '2nd_manual')\n","        if osp.exists(now_dir):\n","            for img_name in os.listdir(now_dir):\n","                cap = cv2.VideoCapture(osp.join(now_dir, img_name))\n","                ret, img = cap.read()\n","                mmcv.imwrite(\n","                    img[:, :, 0] // 128,\n","                    osp.join(out_dir, 'annotations', 'validation',\n","                             osp.splitext(img_name)[0] + '.png'))\n","\n","        print('Removing the temporary files...')\n","\n","    print('Done!')"],"metadata":{"id":"-P5_l59adnb_","executionInfo":{"status":"ok","timestamp":1752958498991,"user_tz":-330,"elapsed":2417,"user":{"displayName":"Minindu Liyanage","userId":"15262789509466583134"}}},"execution_count":2,"outputs":[]}]}